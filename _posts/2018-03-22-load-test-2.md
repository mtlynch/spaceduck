---
title: 'Sia Load Test Result 2: Real Data Scenario'
layout: post
date: '2018-03-15'
summary: Testing Sia's performance on real world data
tags:
- sia
- load test
permalink: "/load-test-2/"
og_image: "/images/2018-03-15-load-test-1/renter-spending.png"
comments: true
---

Last month, I [announced](/sia-load-test-preview/) the first ever load test of Sia. The load test consists of three distinct test cases:

1. [Worst-case scenario](/load-test-1) (published 2018-03-15)
2. Real data scenario (this report)
3. Best-case scenario

## Results summary

| Metric | Value |
|---------|---------|
| Total uploaded | 4.3 TiB (file bytes)<br />15.4 TiB (absolute bytes) |
| Storage efficiency | 28.3% |
| Total files uploaded | 2,626 |
| Total file contracts created | 62 |
| Total spent | 4377.1 SC<br />$61.07\* USD |
| $ per TB/month | $4.51\*\* |
| Total test time | 231.7 hours (9.7 days) |
| Average upload bandwidth | 45.8 Mbps (file data)<br />162.1 Mbps (absolute) |
| Sia crashes | 0 |
| Sia version | 1.3.1 |
| Test OS | Win10 x64 |

\* Based on Siacoin value at test start (1.3951 cents per SC). Assumes that unused renter funds will successfully return to the test wallet at the conclusion of the renter contracts.

\*\*Assumes that a standard renter contract lasts 2.77 months. Excludes bandwidth costs.

## File bytes vs. absolute bytes

*(feel free to skip this if you read this in the [previous report](/load-test-1))*

On traditional cloud storage providers like Amazon S3 or Google Cloud Storage, there is a 1:1 ratio between the size of your files and the amount of data for which you are billed. If you upload 100 GiB of files, you pay for 100 GiB of upload bandwidth and for 100 GiB of storage space.

Sia's costs are more complicated. If you upload 100 GiB of files, the best you can hope for is to pay for 300 GiB in bandwidth and storage (due to Sia's 3x replication). In practice, the cost is not easily predictable, as it depends on how efficiently Sia repackages your files and how reliable your hosts are.

To keep the semantics clear, I introduce two terms for distinguishing between these metrics:

**File bytes** is the total number of bytes in files uploaded to Sia.

**Absolute bytes** is the total amount of data uploaded to hosts, including Sia metadata, file padding, and redundant copies of the data.

If you upload a 100 GiB file and it causes to Sia upload 350 GiB to hosts, that represents a 100 GiB increase in file bytes and a 350 GiB increase in absolute bytes.

## File data bandwidth vs. absolute bandwidth

*(feel free to skip this if you read this in the [previous report](/load-test-1))*

Because of the distinction between file bytes and absolute bytes, a similar disambiguation is required for bandwidth. In this report, I distinguish between file data bandwidth and absolute bandwidth.

The simplest way to explain them is through an example:

1. User uploads a 500 MB file to Sia.
1. Sia breaks this file into 12 equally-sized chunks of ~42 MB each, totaling ~504 MB.
1. Sia uploads each chunk to three different hosts.
1. All uploads complete after 40 seconds.

The file data bandwidth is simply the size of the file divided by the upload duration:

```
= 500 MB / 40 seconds
= 4000 Mb / 40 seconds
= 100 Mbps
```

The absolute bandwidth is the total amount of data transferred divided by the upload duration:

```
= ((42 MB * 12 chunks) * 3 hosts) / 40 seconds
= ((504 MB) * 3 hosts) / 40 seconds
= 1512 MB / 40 seconds
= 12096 Mb / 40 seconds
= 302.4 Mbps
```

## File data bandwidth is what matters

If you have 50 TiB of data to upload to Sia, and you want to know how long this will take, that's the file data bandwidth.

The absolute data bandwidth is useful to guide Sia developers in designing their upload algorithms, but it is not directly relevant to users.

In this report, I focus on file data bandwidth.

## Input data

For this test, I used real data. I still buy Blu-rays and DVDs. Whenever I buy one, I rip it to a raw ISO image. Then I use Handbrake to convert it to mp4s for streaming. I have 4.4 TiB of files total.

This is a realistic test of Sia because I am interested in backing up these files, but even on a low-cost backup solution like AWS Glacier, this would cost about $20/mo, which may not sound so bad until you consider that if I ever needed to recover from a backup, the cost for bandwidth and data retrieval would be about $450.

If I could store this data on Sia for <$10/mo and recover it for <$50 in bandwidth, I'd strongly consider using. Sia does not yet support disaster recovery, but I can begin estimating costs of this scenario now.


| Statistic | Value |
|---|---|
| Minimum file size | 886 bytes |
| Maximum file size | 46.3 GiB |
| Median file size | 343.2 MiB |
| Mean file size | 1.7 GiB |
| Variance | 12.2 GiB |

Of the 2,626 files, 10 were small metadata files (`Thumbs.db` and such) that slipped in. The vast majority of files were well above Sia's 40 MiB chunk size.

{% include image.html file="file-size-histogram.png" alt="File size histogram" fig_caption="Sia 1.3.1 Load Test&#58; Real data - File size histogram" img_link="true" %}

## Storage efficiency

To measure how well Sia stores data, I created the metric of "storage efficiency," which is simply the file bytes divided by the absolute bytes.

On traditional cloud storage providers, efficiency is 100% because you pay for exactly the size of your files. On Sia, the best possible efficiency is 33.3% because Sia uploads every byte of file data at least three times for redundancy. Other factors can degrade efficiency, such as inefficient repackaging of files or unreliable hosts.

{% include image.html file="storage-efficiency.png" alt="Graph of storage efficiency over time" fig_caption="Sia 1.3.1 Load Test&#58; Real Data - Storage efficiency" img_link="true" %}

**Sia stopped uploading new files for XX hours**

The dive begins at about 121 hours elapsed, which is timestamp 2018-03-16 21:03:46Z. The [`renter.log`](https://gist.githubusercontent.com/mtlynch/f31916354e5e5f76ec4da138a77d98ff/raw/bc28fe300accb0aa15037f69e01ec033766c53f1/renter.log) has some interesting log output around that time:

```
2018/03/12 18:51:36.527796 repairscanner.go:330: Repairing 14254 chunks
2018/03/16 19:13:42.836870 repairscanner.go:330: Repairing 81430 chunks
2018/03/18 12:32:02.565418 repairscanner.go:330: Repairing 91865 chunks
```

Slightly before this drop, it decided to repair 81,430 data chunks, which is the equivalent of repairing 3.1 TiB of absolute bytes. But it made similarly outlandish repair declarations on 3/12 and 3/18 and I don't see anything near the same nosedive in efficiency that I see on 3/16.

Why is Sia trying to repair so many chunks at once? At the time it logged the message about repairing 81,430 chunks, Sia's total contract size size was 10.5 TiB. A repair that substantial implies that ~1/3 of Sia's hosts suddenly went offline. It's unlikely that so many hosts would suddenly go offline at once, so my hypothesis is that Sia incorrectly marked chunks for repair before they really needed repairs.

## Cost

{% include image.html file="renter-spending.png" alt="Graph of renter spending over time" fig_caption="Sia 1.3.1 Load Test&#58; Real Data - Renter spending" img_link="true" %}

**Actual storage cost was $4.51 TB/mo**.

This is an interesting result because Sia's standard estimate of storage costs has been $2 per TB/mo for as long as I can remember. It was on the front page of [their website](https://web.archive.org/web/20180128225909/https://sia.tech/) until January 2018.

{% include image.html file="website-estimate.png" alt="Price estimate on Sia website" fig_caption="Storage price estimate on Sia website, captured 2018-01-28." img_link="true" %}

Sia quoted a figure of "$2-3 per TB" on Twitter as recently as [three weeks ago](https://twitter.com/SiaTechHQ/status/968910948953153537).

<blockquote class="twitter-tweet" data-conversation="none" data-lang="en"><p lang="en" dir="ltr">We are currently at about $2-3 per TB per month. Hosts set their own prices, so Siacoin&#39;s valuation does little to affect storage price (hosts are constantly repricing). <br><br>Google Drive&#39;s UI is of course far better, but our goal is to provide a great API for devs to use.</p>&mdash; Sia Tech (@SiaTechHQ) <a href="https://twitter.com/SiaTechHQ/status/968910948953153537?ref_src=twsrc%5Etfw">February 28, 2018</a></blockquote>
<script async src="https://platform.twitter.com/widgets.js" charset="utf-8"></script>

This test showed that the true cost is significantly higher in practice.

To calculate $/TB, I used the following formula:

```
(
  (
    initial_wallet_balance -
      final_remaining_renter_funds -
      final_upload_bandwidth_spending
  ) / file_data_in_tb
) / months_per_contract
```

This is a slightly conservative estimate because it assumes that Sia will cease to accrue upload costs after files are initially uploaded. In reality, Sia continues to spend funds on upload bandwidth while sitting idle because it repairs files as hosts go offline. But bandwidth costs were less than $0.10 per TB, so the difference is negligible.

Note that a naive calculation would be `storage_spending / (file_data_in_tb * months_per_contract)` but such a calculation would ignore costs from contract fees and bugs in Sia.

**48.7% of funds were lost due to bugs**.

I've replicated [bug #2772](https://github.com/NebulousLabs/Sia/issues/2772) in every test I've run. This test was no exception.

As Sia spends money from the 5000 SC allocated for this test, the money should move from the Sia wallet into Sia contracts, maintaining a constant sum of 5000 SC. Instead, Sia spent the full 5000 SC from its wallet, but only ended up with 2,866.7 SC in contract value, leaving 2,133.3 SC missing.

{% include image.html file="funds-balance.png" alt="Graph of renter funds balance over time" fig_caption="Sia 1.3.1 Load Test&#58; Worst-case - Funds split between wallet balance and total contract spending" img_link="true" %}

In response to the previous load test report, Sia's lead developer, David Vorick, [speculated](https://www.reddit.com/r/siacoin/comments/84nh8t/sia_load_test_result_1_worstcase_scenario/dvr9ur8/?st=jf19mq0o&sh=912549ba) that Sia could be spending correctly but accounting incorrectly. In other words, it's possible that Sia actually used the missing 2,133.3 SC to purchase contracts, but the value of those contracts did not appear in Sia's self-reported metrics.

This hypothesis is possible, but it's speculation. Until the Sia team investigates and posts findings on the [bug tracking this issue](https://github.com/NebulousLabs/Sia/issues/2772), I consider the missing amount to be losses due to bugs.

**Sia's cost estimates were inaccurate by a factor of 3**.

Sia offers an API that allows clients to [retrieve price estimates](https://github.com/NebulousLabs/Sia/blob/master/doc/api/Renter.md#json-response-4) before they purchase storage on Sia. [sia_load_tester](https://github.com/mtlynch/sia_load_tester) snapshots the response from this API just before it purchases contracts.

In this test, the estimated prices were as follows:

| Cost | Price Estimate via Sia API |
|------|------------|-----|
| Storage (per TB/mo) | 965.4 SC |
| Upload bandwidth (per TB) | 276.6 SC |
| Contract fees | 562.0 SC |

I uploaded 4.77948797 TB in the test. Based on Sia's reported prices, the total estimated cost for storing this data was:

```
= (965.4 SC/TB/mo * 4.77948797 TB * 2.77 mo) + << storage
  (276.6 SC/TB * 4.77948797 TB) +              << upload bandwidth
  (562.0 SC)                                   << contract fees

= 12781.1 SC +                                 << storage
  1322.0 SC +                                  << upload bandwidth
  562.0 SC                                     << contract fees

= 14665.1 SC                                   << total cost
```

In reality, the total cost was 4377.1 SC, less than 1/3rd of the estimated price.

**Sia-UI's storage estimates were inaccurate by a factor of 8**.

When you set a renter allowance with Sia-UI, it gives you an estimate of how much you can buy with the funds. Sia-UI estimated that 5000 SC would buy 40 TB of space. This estimate is over 8x higher than what 5000 SC purchased in practice.

{% include image.html file="storage-estimate.png" alt="Screenshot of Sia-UI's storage amount estimate" fig_caption="Example screenshot of Sia-UI's storage estimate" img_link="true" %}

I found it strange that Sia's API was drastically overestimating prices while Sia-UI was drastically underestimating prices. If the Sia API thinks 4.8 TB costs 14,665.1 SC, why does Sia-UI think you can buy 40 TB with only 5,000 SC?

I dove into Sia-UI's [code for calculating storage estimates](https://github.com/NebulousLabs/Sia-UI/blob/e6be3f69901a8e548be42ab83642e440c2277d33/plugins/Files/js/sagas/files.js#L50-L52):

```javascript
const estimate = new BigNumber(SiaAPI.siacoinsToHastings(action.funds))
    .dividedBy(response.storageterabytemonth).times(1e12)

yield put(actions.setStorageEstimate(
    '~' + readableFilesize(estimate.toPrecision(1))))
```

This calculation suffers from two flaws:

* It assumes that contract fees and upload costs are zero.
* It treats the Sia API's estimate of cost per month as a cost per contract term, which is 12 weeks.

I filed [bug #775](https://github.com/NebulousLabs/Sia-UI/issues/775) to track this.

## Upload bandwidth

The test uploaded 4.3 TiB of file data in 231.7 hours. That's equivalent to an overall average upload bandwidth of 45.8 Mbps.

*Caveat: Bandwidth measurements in this test are non-rigorous due to the limitations of the test infrastructure. I ran these tests from my home on a  consumer FiOS connection. It offers no bandwidth guarantees and I also used my connection for other bandwidth-intensive activities while the test was in progress. Sia's capabilities could be higher.*

**Bandwidth was strong for the first 2.5 TiB**.

For the first 75 hours of the test (until about 2.5 TiB of file data uploaded), Sia's bandwidth hovered between 75 to 100 Mbps, which is very impressive. It's slower than

{% include image.html file="upload-bandwidth-file-data.png" alt="Graph of upload bandwidth over time" fig_caption="Sia 1.3.1 Load Test&#58; Real Data - Upload bandwidth (file data)" img_link="true" %}


Test terminated when absolute bandwidth dropped below 3 Mbps, which is one of the exit conditions defined in the [test plan](http://localhost:4001/files/sia-load-test-preview/load-test-plan-2018-02-14.pdf).

## API latency

All the metrics shown in this report come from three Sia daemon APIs that [sia_metrics_collector](https://github.com/mtlynch/sia_metrics_collector) polls:

* `/renter/contracts`
* `/renter/files`
* `/wallet`

The API latency is the total amount of time required to call these three APIs in sequence:

{% include image.html file="api-latency.png" alt="Graph of API latency over time" fig_caption="Sia 1.3.1 Load Test&#58; Real Data - API Latency" img_link="true" %}

No bursts

Very regular floor

## Raw data

* [Logs](https://gist.github.com/mtlynch/f31916354e5e5f76ec4da138a77d98ff)
* [Metrics](https://docs.google.com/spreadsheets/d/1HJ1c2bFonXPhVdvrovM-MenZQ16VIfqOqPrnrDZGRbc/edit?usp=sharing)

## Test notes

* Sia v1.3.2 was [released](https://github.com/NebulousLabs/Sia/releases/tag/v1.3.2) while this test was running. While all cases in this load test will use 1.3.1 for consistency, the 1.3.2 release may affect results as hosts upgrade to the latest Sia version.
* The load test script crashed at 2018-03-12 03:17:48Z (at the 7.23 hours elapsed mark). It was down for approximately 40 minutes. During this time, upload bandwidth drops to zero, but this is due to testing error rather than Sia underperformance. All other bandwidth measurements in the test are accurate measures of Sia's performance.
* I did not track CPU/RAM usage rigorously during this test, but I did note that at one point, Sia's RAM usage reached 11.5 GB. [Process Explorer reported](/images/2018-03-22-load-test-2/process-stats.png) that its total virtual memory usage was over 46 GB.

## Reproducing results

All steps to reproduce these results are available in the [sia_load_tester](https://github.com/mtlynch/sia_load_tester/blob/2802acc77d6651bec88cf954c5240197bc6d9627/README.md) README.