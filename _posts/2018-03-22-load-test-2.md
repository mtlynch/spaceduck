---
title: 'Sia Load Test Result 2: Real Data Scenario'
layout: post
date: '2018-03-15'
summary: Testing Sia's performance on real world data
tags:
- sia
- load test
permalink: "/load-test-2/"
og_image: "/images/2018-03-15-load-test-1/renter-spending.png"
comments: true
---

Last month, I [announced](/sia-load-test-preview/) the first ever load test of Sia. The load test consists of three distinct test cases:

1. [Worst-case scenario](/load-test-1) (published 2018-03-15)
2. Real data scenario (this report)
3. Best-case scenario

## Results summary

| Metric | Value |
|---------|---------|
| Total uploaded | 4.3 TiB (file bytes)<br />15.4 TiB (absolute bytes) |
| Storage efficiency | 28.3% |
| Total files uploaded | 2,626 |
| Total file contracts created | 62 |
| Total spent | 4377.1 SC<br />$61.07\* USD |
| $ per TB/month | $4.51\*\* |
| Total test time | 231.7 hours (9.7 days) |
| Average upload bandwidth | 45.8 Mbps (file data)<br />162.1 Mbps (absolute) |
| Sia crashes | 0 |
| Sia version | 1.3.1 |
| Test OS | Win10 x64 |

\* Based on Siacoin value at test start (1.3951 cents per SC). Assumes that unused renter funds will successfully return to the test wallet at the conclusion of the renter contracts.

\*\*Assumes that a standard renter contract lasts 2.77 months. Excludes bandwidth costs.

## File bytes vs. absolute bytes

*(feel free to skip this if you read this in the [previous report](/load-test-1))*

On traditional cloud storage providers like Amazon S3 or Google Cloud Storage, there is a 1:1 ratio between the size of your files and the amount of data for which you are billed. If you upload 100 GiB of files, you pay for 100 GiB of upload bandwidth and for 100 GiB of storage space.

Sia's costs are more complicated. If you upload 100 GiB of files, the best you can hope for is to pay for 300 GiB in bandwidth and storage (due to Sia's 3x replication). In practice, the cost is not easily predictable, as it depends on how efficiently Sia repackages your files and how reliable your hosts are.

To keep the semantics clear, I introduce two terms for distinguishing between these metrics:

**File bytes** is the total number of bytes in files uploaded to Sia.

**Absolute bytes** is the total amount of data uploaded to hosts, including Sia metadata, file padding, and redundant copies of the data.

If you upload a 100 GiB file and it causes to Sia upload 350 GiB to hosts, that represents a 100 GiB increase in file bytes and a 350 GiB increase in absolute bytes.

## File data bandwidth vs. absolute bandwidth

*(feel free to skip this if you read this in the [previous report](/load-test-1))*

Because of the distinction between file bytes and absolute bytes, a similar disambiguation is required for bandwidth. In this report, I distinguish between file data bandwidth and absolute bandwidth.

The simplest way to explain them is through an example:

1. User uploads a 500 MB file to Sia.
1. Sia breaks this file into 12 equally-sized chunks of ~42 MB each, totaling ~504 MB.
1. Sia uploads each chunk to three different hosts.
1. All uploads complete after 40 seconds.

The file data bandwidth is simply the size of the file divided by the upload duration:

```
= 500 MB / 40 seconds
= 4000 Mb / 40 seconds
= 100 Mbps
```

The absolute bandwidth is the total amount of data transferred divided by the upload duration:

```
= ((42 MB * 12 chunks) * 3 hosts) / 40 seconds
= ((504 MB) * 3 hosts) / 40 seconds
= 1512 MB / 40 seconds
= 12096 Mb / 40 seconds
= 302.4 Mbps
```

## File data bandwidth is what matters

If you have 50 TiB of data to upload to Sia, and you want to know how long this will take, that's the file data bandwidth.

The absolute data bandwidth is useful to guide Sia developers in designing their upload algorithms, but it is not directly relevant to users.

In this report, I focus on file data bandwidth.

## Input data

For this test, I used real data. I still buy Blu-rays and DVDs. Whenever I buy one, I rip it to a raw ISO image. Then I use Handbrake to convert it to mp4s for streaming. I have 4.4 TiB of files total.

This is a realistic test of Sia because I am interested in backing up these files, but even on a low-cost backup solution like AWS Glacier, this would cost about $20/mo, which may not sound so bad until you consider that if I ever needed to recover from a backup, the cost for bandwidth and data retrieval would be about $450.

If I could store this data on Sia for <$10/mo and recover it for <$50 in bandwidth, I'd strongly consider using. This won't be possible in practice until Sia supports data recovery, but I can begin estimating costs now.


| Statistic | Value |
|---|---|
| Minimum file size | 886 bytes |
| Maximum file size | 46.3 GiB |
| Median file size | 343.2 MiB |
| Mean file size | 1.7 GiB |
| Variance | 12.2 GiB |

There were 10 small metadata files (`Thumbs.db` and such) that slipped in, but the vast majority of files were well above Sia's  40 MiB chunk size.

{% include image.html file="file-size-histogram.png" alt="File size histogram" fig_caption="Sia 1.3.1 Load Test&#58; Real data - File size histogram" img_link="true" %}

## Storage efficiency

To measure how well Sia stores data, I created the metric of "storage efficiency," which is simply the file bytes divided by the absolute bytes.

On traditional cloud storage providers, efficiency is 100% because you pay for exactly the size of your files. On Sia, the best possible efficiency is 33.3% because Sia uploads every byte of file data at least three times for redundancy. Other factors can degrade efficiency, such as inefficient repackaging of files or unreliable hosts.

The dive begins at about 121 hours elapsed, which is timestamp 2018-03-16 21:03:46Z. The [`renter.log`](https://gist.githubusercontent.com/mtlynch/f31916354e5e5f76ec4da138a77d98ff/raw/bc28fe300accb0aa15037f69e01ec033766c53f1/renter.log) has some interesting log output around that time:

```
2018/03/12 18:51:36.527796 repairscanner.go:330: Repairing 14254 chunks
2018/03/16 19:13:42.836870 repairscanner.go:330: Repairing 81430 chunks
2018/03/18 12:32:02.565418 repairscanner.go:330: Repairing 91865 chunks
```

Slightly before this drop, it decided to repair 81,430 data chunks, which is the equivalent of repairing 3.1 TiB of absolute bytes. But it made similarly outlandish repair declarations on 3/12 and 3/18 and I don't see anything near the same nosedive in efficiency that I see on 3/16.

Why is Sia trying to repair so many chunks at once? At the time it logged the message about repairing 81,430 chunks, Sia's total contract size size was 10.5 TiB. A repair that substantial implies that ~1/3 of Sia's hosts suddenly went offline. It's unlikely that so many hosts would suddenly go offline at once, so my hypothesis is that Sia incorrectly marked chunks for repair before they really needed repairs.

## Cost

**Storage cost per TB/mo was $4.51**. This is an interesting result because Sia's standard estimate of storage costs has been $2 per TB/mo for as long as I can remember. It was on the front page of [their website](https://web.archive.org/web/20180104073321/https://sia.tech/) until January 2018, and they quoted this figure on Twitter as recently as [three weeks ago](https://twitter.com/SiaTechHQ/status/968910948953153537).

To calculate $/TB, I used the following formula:

```
(
  (
    initial_wallet_balance -
      remaining_renter_funds -
      upload_bandwidth_spending
  ) / file_data_in_tb
) / months_per_contract
```

This is a slightly conservative estimate because it assumes that Sia will cease to accrue upload costs after files are initially uploaded. In practice, Sia will accrue upload costs from sitting idle because it repairs files as hosts go offline. Bandwidth costs are almost negligible, so even assuming 100% reuploads every contract period only increases the figure to $4.61 per TB/mo.

**48.7% of spending was lost due to bugs**.

In response to the previous load test report, Sia's lead developer, David Vorick, [speculated](https://www.reddit.com/r/siacoin/comments/84nh8t/sia_load_test_result_1_worstcase_scenario/dvr9ur8/?st=jf19mq0o&sh=912549ba) that Sia could be spending correctly but accounting incorrectly. In other words, it's possible that Sia actually used the missing 2133.3 SC to purchase contracts, but the value of those contracts did not appear in Sia's self-reported metrics.

This hypothesis is possible, but it's speculation. Until the Sia team investigates and posts findings on the [bug tracking this issue](https://github.com/NebulousLabs/Sia/issues/2772), I consider the missing amount to be losses due to bugs.

**Sia's cost and storage estimates are radically inaccurate**.

| Cost | Estimated | Actual | Delta |
|------|------------|-----|
| Storage (TB/mo) | 211.2 SC | 113.9 SC | - |
| Upload bandwidth (per TB) | 276.6 SC | 19.73 SC | -92.9% |
| Contract fees | 562.0 SC | 640.6 SC | +14.0% |
| Lost funds | 0 SC | 2133.3 | + Inf. |


**Costs are difficult to predict**.

## Upload bandwidth

The test uploaded 4.3 TiB of file data in 231.7 hours. That's equivalent to an upload bandwidth of 45.8 Mbps.

*Caveat: Bandwidth measurements in this test are non-rigorous due to the limitations of the test infrastructure. I ran these tests from my home on a  consumer FiOS connection. It offers no bandwidth guarantees and I also used my connection for other bandwidth-intensive activities while the test was in progress. Sia's capabilities could be higher.*

**Bandwidth was strong for the first 2.5 TiB**. For the first 75 hours of the test (until about 2.5 TiB of file data uploaded), Sia'a bandwidth hovered between 75 to 100 Mbps, which is very impressive. It's slower than


## API latency

All the metrics shown in this report come from three Sia daemon APIs that [sia_metrics_collector](https://github.com/mtlynch/sia_metrics_collector) polls:

* `/renter/contracts`
* `/renter/files`
* `/wallet`

The API latency is the total amount of time required to call these three APIs in sequence:

## Raw data

* [Logs](https://gist.github.com/mtlynch/f31916354e5e5f76ec4da138a77d98ff)
* [Metrics](https://docs.google.com/spreadsheets/d/1HJ1c2bFonXPhVdvrovM-MenZQ16VIfqOqPrnrDZGRbc/edit?usp=sharing)

## Test notes

* Sia v1.3.2 was [released](https://github.com/NebulousLabs/Sia/releases/tag/v1.3.2) while this test was running. While all cases in this load test will use 1.3.1 for consistency, the 1.3.2 release may affect results as hosts upgrade to the latest Sia version.
* The load test script crashed at 2018-03-12 03:17:48Z (at the 7.23 hours elapsed mark). It was down for approximately 40 minutes. During this time, upload bandwidth drops to zero, but this is due to testing error rather than Sia underperformance. All other bandwidth measurements in the test are accurate measures of Sia's performance.
* I did not track CPU/RAM usage rigorously during this test, but I did note that at one point, Sia's RAM usage reached 11.5 GB. Process Explorer reported that its total virtual memory usage was over 46 GB. (TODO: link)

## Reproducing results

All steps to reproduce these results are available in the [sia_load_tester](https://github.com/mtlynch/sia_load_tester/blob/2802acc77d6651bec88cf954c5240197bc6d9627/README.md) README.